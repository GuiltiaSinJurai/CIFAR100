{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Image Recognition\n",
    "===\n",
    "\n",
    "This notebook will create a convolutional neural network to classify images in either the mnist or cifar-10 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow and numpy to create the neural network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib to plot info to show our results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# OS to load files and save checkpoints|\n",
    "import os\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "---\n",
    "\n",
    "This code will load the dataset that you'll use to train and test the model.\n",
    "\n",
    "The code provided will load the mnist or cifar data from files, you'll need to add the code that processes it into a format your neural network can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST\n",
    "---\n",
    "\n",
    "Run this cell to load mnist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load MNIST data from tf examples\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10\n",
    "---\n",
    "\n",
    "Run this cell to load cifar-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])\n",
      "training data length: 50000\n",
      "eval_data: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load cifar data from file\n",
    "\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "\n",
    "color_channels = 3\n",
    "\n",
    "model_name = \"cifar\"\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "cifar_path = './cifar-100-python/'\n",
    "\n",
    "train_data = np.array([])\n",
    "train_labels = np.array([])\n",
    "\n",
    "# Load all the data batches.\n",
    "data_batch = unpickle(cifar_path + 'train')\n",
    "print(data_batch.keys())\n",
    "\n",
    "\n",
    "train_data = data_batch[b'data']\n",
    "train_labels = data_batch[b'coarse_labels']\n",
    "\n",
    "\n",
    "# Load the eval batch.\n",
    "eval_batch = unpickle(cifar_path + 'test')\n",
    "\n",
    "eval_data = eval_batch[b'data']\n",
    "eval_labels = eval_batch[b'coarse_labels'] \n",
    "\n",
    "# Load the english category names.\n",
    "category_names_bytes = unpickle(cifar_path + 'meta')[b'coarse_label_names']\n",
    "category_names = list(map(lambda x: x.decode(\"utf-8\"), category_names_bytes))\n",
    "\n",
    "# TODO: Process Cifar data\n",
    "def process_data(data):\n",
    "    float_data = np.array(data, dtype = float) / 255.0\n",
    "    \n",
    "    reshaped_data = np.reshape(float_data, (-1, color_channels, image_height, image_width))\n",
    "    \n",
    "    transposed_data = np.transpose(reshaped_data, [0, 2, 3, 1])\n",
    "    #plt.imshow(transposed_data[0])\n",
    "    \n",
    "    return transposed_data\n",
    "            \n",
    "train_data = process_data(train_data)\n",
    "eval_data = process_data(eval_data)\n",
    "\n",
    "\n",
    "print(\"training data length:\",len(train_data))\n",
    "print(\"eval_data:\",len(eval_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is processed, you have a few variables for the data itself and info about its shape:\n",
    "\n",
    "### Model Info\n",
    "\n",
    "- **image_height, image_width** - The height and width of the processed images\n",
    "- **color_channels** - the number of color channels in the image. This will be either 1 for grayscale or 3 for rgb.\n",
    "- **model_name** - either \"cifar\" or \"mnist\" - if you need to handle anything differently based on the model, check this variable.\n",
    "- **category_names** - strings for each category name (used to print out labels when testing results)\n",
    "\n",
    "### Training Data\n",
    "\n",
    "- **train_data** - the training data images\n",
    "- **train_labels** - the labels for the training data - the \"answer key\"\n",
    "\n",
    "### Evaluation Data\n",
    "\n",
    "- **eval_data** - Image data for evaluation. A different set of images to test your network's effectiveness.\n",
    "- **eval_labels** - the answer key for evaluation data.\n",
    "\n",
    "Building the Neural Network Model\n",
    "--\n",
    "\n",
    "Next, you'll build a neural network with the following architecture:\n",
    "\n",
    "- An input placeholder that takes one or more images.\n",
    "- 1st Convolutional layer with 32 filters and a kernel size of 5x5 and same padding\n",
    "- 1st Pooling layer with a 2x2 pool size and stride of 2\n",
    "- 2nd Convolutional layer with 64 filters and a kernel size of 5x5 and same padding\n",
    "- 2nd Pooling layer with a 2x2 pool size and stride of 2\n",
    "- Flatten the pooling layer\n",
    "- A fully connected layer with 1024 units\n",
    "- A dropout layer with a rate of 0.4\n",
    "- An output layer with an output size equal to the number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n",
      "Tensor(\"conv2d/Relu:0\", shape=(?, 32, 32, 32), dtype=float32)\n",
      "(?, 16, 16, 32)\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "(?, 8, 8, 64)\n",
      "(?, 1024)\n",
      "(?, 20)\n"
     ]
    }
   ],
   "source": [
    "# TODO: The neural network\n",
    "class ConvNet:\n",
    "    def __init__(self, image_height, image_width, channels, num_classes):\n",
    "        self.input_layer = tf.placeholder(dtype=tf.float32, shape = [None, image_height, image_width, channels], name='inputs')\n",
    "        print(self.input_layer.shape)\n",
    "        \n",
    "        self.labels = tf.placeholder(dtype=tf.float32, shape = [None, num_classes])\n",
    "        \n",
    "        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size=[5, 5], padding='same', activation = tf.nn.relu)\n",
    "        print(conv_layer_1)\n",
    "        \n",
    "        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[2, 2], strides = 2)\n",
    "        print(pooling_layer_1.shape)\n",
    "        \n",
    "        conv_layer_2 = tf.layers.conv2d(pooling_layer_1, filters = 64, kernel_size=[5, 5], padding='same', activation = tf.nn.relu)\n",
    "        print(conv_layer_2)\n",
    "        \n",
    "        pooling_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=[2, 2], strides = 2)\n",
    "        print(pooling_layer_2.shape)\n",
    "        \n",
    "        flattened_pooling = tf.layers.flatten(pooling_layer_2)\n",
    "        dense_layer = tf.layers.dense(flattened_pooling, 1024, activation=tf.nn.relu)\n",
    "        print(dense_layer.shape)\n",
    "        \n",
    "        dropout = tf.layers.dropout(dense_layer, rate = 0.4, training=True)\n",
    "        \n",
    "        outputs = tf.layers.dense(dropout, num_classes)\n",
    "        print(outputs.shape)\n",
    "        \n",
    "        self.choice = tf.argmax(outputs, axis=1)\n",
    "        self.probability = tf.nn.softmax(outputs)\n",
    "        \n",
    "        self.labels = tf.placeholder(dtype=tf.float32, name = 'labels')\n",
    "        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice)\n",
    "        \n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=outputs)\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\n",
    "        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "CNN = ConvNet(32,32,3,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training Process\n",
    "---\n",
    "\n",
    "The cells below will set up and run the training process.\n",
    "\n",
    "- Set up initial values for batch size, training length.\n",
    "- Process data into batched datasets to feed into the network.\n",
    "- Run through batches of training data, update weights, save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: initialize variables\n",
    "training_steps = 20000\n",
    "batch_size = 100\n",
    "\n",
    "path = '/' + model_name + '-cnn/'\n",
    "\n",
    "load_checkpoint = False\n",
    "\n",
    "performance_graph = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n",
      "Tensor(\"conv2d/Relu:0\", shape=(?, 32, 32, 32), dtype=float32)\n",
      "(?, 16, 16, 32)\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "(?, 8, 8, 64)\n",
      "(?, 1024)\n",
      "(?, 20)\n",
      "Accuracy at step 100: 0.0654455\n",
      "Saving checkpoint\n",
      "Accuracy at step 200: 0.080398\n",
      "Saving checkpoint\n",
      "Accuracy at step 300: 0.0936877\n",
      "Saving checkpoint\n",
      "Accuracy at step 400: 0.105611\n",
      "Saving checkpoint\n",
      "Accuracy at step 500: 0.116407\n",
      "Saving checkpoint\n",
      "Accuracy at step 600: 0.126273\n",
      "Saving checkpoint\n",
      "Accuracy at step 700: 0.134565\n",
      "Saving checkpoint\n",
      "Accuracy at step 800: 0.142222\n",
      "Saving checkpoint\n",
      "Accuracy at step 900: 0.149367\n",
      "Saving checkpoint\n",
      "Accuracy at step 1000: 0.155564\n",
      "Saving checkpoint\n",
      "Accuracy at step 1100: 0.161662\n",
      "Saving checkpoint\n",
      "Accuracy at step 1200: 0.167377\n",
      "Saving checkpoint\n",
      "Accuracy at step 1300: 0.172744\n",
      "Saving checkpoint\n",
      "Accuracy at step 1400: 0.177345\n",
      "Saving checkpoint\n",
      "Accuracy at step 1500: 0.182278\n",
      "Saving checkpoint\n",
      "Accuracy at step 1600: 0.18722\n",
      "Saving checkpoint\n",
      "Accuracy at step 1700: 0.191452\n",
      "Saving checkpoint\n",
      "Accuracy at step 1800: 0.19568\n",
      "Saving checkpoint\n",
      "Accuracy at step 1900: 0.199921\n",
      "Saving checkpoint\n",
      "Accuracy at step 2000: 0.203893\n",
      "Saving checkpoint\n",
      "Accuracy at step 2100: 0.207834\n",
      "Saving checkpoint\n",
      "Accuracy at step 2200: 0.211845\n",
      "Saving checkpoint\n",
      "Accuracy at step 2300: 0.215254\n",
      "Saving checkpoint\n",
      "Accuracy at step 2400: 0.218567\n",
      "Saving checkpoint\n",
      "Accuracy at step 2500: 0.221627\n",
      "Saving checkpoint\n",
      "Accuracy at step 2600: 0.224548\n",
      "Saving checkpoint\n",
      "Accuracy at step 2700: 0.227505\n",
      "Saving checkpoint\n",
      "Accuracy at step 2800: 0.230361\n",
      "Saving checkpoint\n",
      "Accuracy at step 2900: 0.233075\n",
      "Saving checkpoint\n",
      "Accuracy at step 3000: 0.235978\n",
      "Saving checkpoint\n",
      "Accuracy at step 3100: 0.238826\n",
      "Saving checkpoint\n",
      "Accuracy at step 3200: 0.241384\n",
      "Saving checkpoint\n",
      "Accuracy at step 3300: 0.244026\n",
      "Saving checkpoint\n",
      "Accuracy at step 3400: 0.246786\n",
      "Saving checkpoint\n",
      "Accuracy at step 3500: 0.249234\n",
      "Saving checkpoint\n",
      "Accuracy at step 3600: 0.251844\n",
      "Saving checkpoint\n",
      "Accuracy at step 3700: 0.254148\n",
      "Saving checkpoint\n",
      "Accuracy at step 3800: 0.256556\n",
      "Saving checkpoint\n",
      "Accuracy at step 3900: 0.258711\n",
      "Saving checkpoint\n",
      "Accuracy at step 4000: 0.260837\n",
      "Saving checkpoint\n",
      "Accuracy at step 4100: 0.262963\n",
      "Saving checkpoint\n",
      "Accuracy at step 4200: 0.265094\n",
      "Saving checkpoint\n",
      "Accuracy at step 4300: 0.267263\n",
      "Saving checkpoint\n",
      "Accuracy at step 4400: 0.269382\n",
      "Saving checkpoint\n",
      "Accuracy at step 4500: 0.271415\n",
      "Saving checkpoint\n",
      "Accuracy at step 4600: 0.273401\n",
      "Saving checkpoint\n",
      "Accuracy at step 4700: 0.275414\n",
      "Saving checkpoint\n",
      "Accuracy at step 4800: 0.27734\n",
      "Saving checkpoint\n",
      "Accuracy at step 4900: 0.279461\n",
      "Saving checkpoint\n",
      "Accuracy at step 5000: 0.281112\n",
      "Saving checkpoint\n",
      "Accuracy at step 5100: 0.282882\n",
      "Saving checkpoint\n",
      "Accuracy at step 5200: 0.284874\n",
      "Saving checkpoint\n",
      "Accuracy at step 5300: 0.286553\n",
      "Saving checkpoint\n",
      "Accuracy at step 5400: 0.288104\n",
      "Saving checkpoint\n",
      "Accuracy at step 5500: 0.289944\n",
      "Saving checkpoint\n",
      "Accuracy at step 5600: 0.291519\n",
      "Saving checkpoint\n",
      "Accuracy at step 5700: 0.29334\n",
      "Saving checkpoint\n",
      "Accuracy at step 5800: 0.295127\n",
      "Saving checkpoint\n",
      "Accuracy at step 5900: 0.296807\n",
      "Saving checkpoint\n",
      "Accuracy at step 6000: 0.298429\n",
      "Saving checkpoint\n",
      "Accuracy at step 6100: 0.300162\n",
      "Saving checkpoint\n",
      "Accuracy at step 6200: 0.301698\n",
      "Saving checkpoint\n",
      "Accuracy at step 6300: 0.303219\n",
      "Saving checkpoint\n",
      "Accuracy at step 6400: 0.304756\n",
      "Saving checkpoint\n",
      "Accuracy at step 6500: 0.306221\n",
      "Saving checkpoint\n",
      "Accuracy at step 6600: 0.307823\n",
      "Saving checkpoint\n",
      "Accuracy at step 6700: 0.309352\n",
      "Saving checkpoint\n",
      "Accuracy at step 6800: 0.310985\n",
      "Saving checkpoint\n",
      "Accuracy at step 6900: 0.312239\n",
      "Saving checkpoint\n",
      "Accuracy at step 7000: 0.313654\n",
      "Saving checkpoint\n",
      "Accuracy at step 7100: 0.315194\n",
      "Saving checkpoint\n",
      "Accuracy at step 7200: 0.316698\n",
      "Saving checkpoint\n",
      "Accuracy at step 7300: 0.317958\n",
      "Saving checkpoint\n",
      "Accuracy at step 7400: 0.319355\n",
      "Saving checkpoint\n",
      "Accuracy at step 7500: 0.320765\n",
      "Saving checkpoint\n",
      "Accuracy at step 7600: 0.322196\n",
      "Saving checkpoint\n",
      "Accuracy at step 7700: 0.323577\n",
      "Saving checkpoint\n",
      "Accuracy at step 7800: 0.325004\n",
      "Saving checkpoint\n",
      "Accuracy at step 7900: 0.326297\n",
      "Saving checkpoint\n",
      "Accuracy at step 8000: 0.327522\n",
      "Saving checkpoint\n",
      "Accuracy at step 8100: 0.328837\n",
      "Saving checkpoint\n",
      "Accuracy at step 8200: 0.330187\n",
      "Saving checkpoint\n",
      "Accuracy at step 8300: 0.331442\n",
      "Saving checkpoint\n",
      "Accuracy at step 8400: 0.332721\n",
      "Saving checkpoint\n",
      "Accuracy at step 8500: 0.333851\n",
      "Saving checkpoint\n",
      "Accuracy at step 8600: 0.335153\n",
      "Saving checkpoint\n",
      "Accuracy at step 8700: 0.336444\n",
      "Saving checkpoint\n",
      "Accuracy at step 8800: 0.337722\n",
      "Saving checkpoint\n",
      "Accuracy at step 8900: 0.338881\n",
      "Saving checkpoint\n",
      "Accuracy at step 9000: 0.340148\n",
      "Saving checkpoint\n",
      "Accuracy at step 9100: 0.341386\n",
      "Saving checkpoint\n",
      "Accuracy at step 9200: 0.342595\n",
      "Saving checkpoint\n",
      "Accuracy at step 9300: 0.34371\n",
      "Saving checkpoint\n",
      "Accuracy at step 9400: 0.344843\n",
      "Saving checkpoint\n",
      "Accuracy at step 9500: 0.346037\n",
      "Saving checkpoint\n",
      "Accuracy at step 9600: 0.347277\n",
      "Saving checkpoint\n",
      "Accuracy at step 9700: 0.348403\n",
      "Saving checkpoint\n",
      "Accuracy at step 9800: 0.349607\n",
      "Saving checkpoint\n",
      "Accuracy at step 9900: 0.350745\n",
      "Saving checkpoint\n",
      "Accuracy at step 10000: 0.351834\n",
      "Saving checkpoint\n",
      "Accuracy at step 10100: 0.353066\n",
      "Saving checkpoint\n",
      "Accuracy at step 10200: 0.354083\n",
      "Saving checkpoint\n",
      "Accuracy at step 10300: 0.355229\n",
      "Saving checkpoint\n",
      "Accuracy at step 10400: 0.356356\n",
      "Saving checkpoint\n",
      "Accuracy at step 10500: 0.357456\n",
      "Saving checkpoint\n",
      "Accuracy at step 10600: 0.358626\n",
      "Saving checkpoint\n",
      "Accuracy at step 10700: 0.35981\n",
      "Saving checkpoint\n",
      "Accuracy at step 10800: 0.360928\n",
      "Saving checkpoint\n",
      "Accuracy at step 10900: 0.361939\n",
      "Saving checkpoint\n",
      "Accuracy at step 11000: 0.362965\n",
      "Saving checkpoint\n",
      "Accuracy at step 11100: 0.364097\n",
      "Saving checkpoint\n",
      "Accuracy at step 11200: 0.365175\n",
      "Saving checkpoint\n",
      "Accuracy at step 11300: 0.366244\n",
      "Saving checkpoint\n",
      "Accuracy at step 11400: 0.367266\n",
      "Saving checkpoint\n",
      "Accuracy at step 11500: 0.368349\n",
      "Saving checkpoint\n",
      "Accuracy at step 11600: 0.369441\n",
      "Saving checkpoint\n",
      "Accuracy at step 11700: 0.370542\n",
      "Saving checkpoint\n",
      "Accuracy at step 11800: 0.371675\n",
      "Saving checkpoint\n",
      "Accuracy at step 11900: 0.372726\n",
      "Saving checkpoint\n",
      "Accuracy at step 12000: 0.373721\n",
      "Saving checkpoint\n",
      "Accuracy at step 12100: 0.374852\n",
      "Saving checkpoint\n",
      "Accuracy at step 12200: 0.375894\n",
      "Saving checkpoint\n",
      "Accuracy at step 12300: 0.376966\n",
      "Saving checkpoint\n",
      "Accuracy at step 12400: 0.377978\n",
      "Saving checkpoint\n",
      "Accuracy at step 12500: 0.378967\n",
      "Saving checkpoint\n",
      "Accuracy at step 12600: 0.38006\n",
      "Saving checkpoint\n",
      "Accuracy at step 12700: 0.381153\n",
      "Saving checkpoint\n",
      "Accuracy at step 12800: 0.382144\n",
      "Saving checkpoint\n",
      "Accuracy at step 12900: 0.383111\n",
      "Saving checkpoint\n",
      "Accuracy at step 13000: 0.384033\n",
      "Saving checkpoint\n",
      "Accuracy at step 13100: 0.385052\n",
      "Saving checkpoint\n",
      "Accuracy at step 13200: 0.386018\n",
      "Saving checkpoint\n",
      "Accuracy at step 13300: 0.38706\n",
      "Saving checkpoint\n",
      "Accuracy at step 13400: 0.388043\n",
      "Saving checkpoint\n",
      "Accuracy at step 13500: 0.389022\n",
      "Saving checkpoint\n",
      "Accuracy at step 13600: 0.390086\n",
      "Saving checkpoint\n",
      "Accuracy at step 13700: 0.391121\n",
      "Saving checkpoint\n",
      "Accuracy at step 13800: 0.392097\n",
      "Saving checkpoint\n",
      "Accuracy at step 13900: 0.393068\n",
      "Saving checkpoint\n",
      "Accuracy at step 14000: 0.393988\n",
      "Saving checkpoint\n",
      "Accuracy at step 14100: 0.395038\n",
      "Saving checkpoint\n",
      "Accuracy at step 14200: 0.396016\n",
      "Saving checkpoint\n",
      "Accuracy at step 14300: 0.397016\n",
      "Saving checkpoint\n",
      "Accuracy at step 14400: 0.397969\n",
      "Saving checkpoint\n",
      "Accuracy at step 14500: 0.398904\n",
      "Saving checkpoint\n",
      "Accuracy at step 14600: 0.399882\n",
      "Saving checkpoint\n",
      "Accuracy at step 14700: 0.400918\n",
      "Saving checkpoint\n",
      "Accuracy at step 14800: 0.401855\n",
      "Saving checkpoint\n",
      "Accuracy at step 14900: 0.402805\n",
      "Saving checkpoint\n",
      "Accuracy at step 15000: 0.403754\n",
      "Saving checkpoint\n",
      "Accuracy at step 15100: 0.404787\n",
      "Saving checkpoint\n",
      "Accuracy at step 15200: 0.405771\n",
      "Saving checkpoint\n",
      "Accuracy at step 15300: 0.4067\n",
      "Saving checkpoint\n",
      "Accuracy at step 15400: 0.407614\n",
      "Saving checkpoint\n",
      "Accuracy at step 15500: 0.408536\n",
      "Saving checkpoint\n",
      "Accuracy at step 15600: 0.409578\n",
      "Saving checkpoint\n",
      "Accuracy at step 15700: 0.410545\n",
      "Saving checkpoint\n",
      "Accuracy at step 15800: 0.411518\n",
      "Saving checkpoint\n",
      "Accuracy at step 15900: 0.412397\n",
      "Saving checkpoint\n",
      "Accuracy at step 16000: 0.413267\n",
      "Saving checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at step 16100: 0.414267\n",
      "Saving checkpoint\n",
      "Accuracy at step 16200: 0.415242\n",
      "Saving checkpoint\n",
      "Accuracy at step 16300: 0.416178\n",
      "Saving checkpoint\n",
      "Accuracy at step 16400: 0.417099\n",
      "Saving checkpoint\n",
      "Accuracy at step 16500: 0.417998\n",
      "Saving checkpoint\n",
      "Accuracy at step 16600: 0.418924\n",
      "Saving checkpoint\n",
      "Accuracy at step 16700: 0.419885\n",
      "Saving checkpoint\n",
      "Accuracy at step 16800: 0.420801\n",
      "Saving checkpoint\n",
      "Accuracy at step 16900: 0.421721\n",
      "Saving checkpoint\n",
      "Accuracy at step 17000: 0.422589\n",
      "Saving checkpoint\n",
      "Accuracy at step 17100: 0.423574\n",
      "Saving checkpoint\n",
      "Accuracy at step 17200: 0.424485\n",
      "Saving checkpoint\n",
      "Accuracy at step 17300: 0.4254\n",
      "Saving checkpoint\n",
      "Accuracy at step 17400: 0.426308\n",
      "Saving checkpoint\n",
      "Accuracy at step 17500: 0.427191\n",
      "Saving checkpoint\n",
      "Accuracy at step 17600: 0.428177\n",
      "Saving checkpoint\n",
      "Accuracy at step 17700: 0.429179\n",
      "Saving checkpoint\n",
      "Accuracy at step 17800: 0.430047\n",
      "Saving checkpoint\n",
      "Accuracy at step 17900: 0.430987\n",
      "Saving checkpoint\n",
      "Accuracy at step 18000: 0.431904\n",
      "Saving checkpoint\n",
      "Accuracy at step 18100: 0.43283\n",
      "Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement the training loop\n",
    "tf.reset_default_graph()\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "dataset = dataset.shuffle(buffer_size = len(train_labels))\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "dataset_iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "next_element = dataset_iterator.get_next()\n",
    "\n",
    "cnn = ConvNet (image_height, image_width, color_channels, 20)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    if load_checkpoint:\n",
    "        checkpoint = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        \n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(dataset_iterator.initializer)\n",
    "\n",
    "    for step in range(training_steps):\n",
    "        current_batch = sess.run(next_element)\n",
    "        \n",
    "        batch_inputs = current_batch[0]\n",
    "        batch_labels = current_batch[1]\n",
    "        \n",
    "        sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict = {cnn.input_layer: batch_inputs, cnn.labels: batch_labels})       \n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            performance_graph = np.append(performance_graph, sess.run(cnn.accuracy))\n",
    "            \n",
    "        if step % 100 == 0 and step > 0:\n",
    "            current_acc = sess.run(cnn.accuracy)\n",
    "        \n",
    "            print(\"Accuracy at step \" + str(step) + \": \" + str(current_acc))\n",
    "            print(\"Saving checkpoint\")\n",
    "            saver.save(sess, path + model_name, step)\n",
    "                 \n",
    "    print(\"Saving final checkpoint for training session.\")\n",
    "    saver.save(sess, path + model_name, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Performance\n",
    "---\n",
    "\n",
    "These cells will evaluate the performance of your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Display graph of performance over time\n",
    "plt.plot(performance_graph)\n",
    "plt.figure().set_facecolor('white')\n",
    "plt.xlabel(\"Steps/10\")\n",
    "plt.ylabel(\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Run through the evaluation data set, check accuracy of model\n",
    "with tf.Session() as sess:\n",
    "    checkpoint = tf.train.get_checkpoint_state(path)\n",
    "    saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "    \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    for image, label in zip(eval_data, eval_labels):\n",
    "        sess.run(cnn.accuracy_op, feed_dict= {cnn.input_layer: [image], cnn.labels:label})\n",
    "    \n",
    "    print(sess.run(cnn.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Get a random set of images and make guesses for each\n",
    "with tf.Session() as sess:\n",
    "    checkpoint = tf.train.get_checkpoint_state(path)\n",
    "    saver.restore(sess,checkpoint.model_checkpoint_path)\n",
    "\n",
    "    indexes = np.random.choice(len(eval_data), 10, replace = False)\n",
    "\n",
    "    rows = 5\n",
    "    cols = 2\n",
    "     \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5,5))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    image_count = 0\n",
    "     \n",
    "    for idx in indexes:\n",
    "        image_count += 1\n",
    "        sub = plt.subplot(rows,cols,image_count)\n",
    "        img = eval_data[idx]\n",
    "        if model_name == \"mnist\":\n",
    "            img = img.reshape(28, 28)\n",
    "        plt.imshow(img)\n",
    "        guess = sess.run(cnn.choice, feed_dict={cnn.input_layer:[eval_data[idx]]})\n",
    "        if model_name == \"mnist\":\n",
    "            guess_name = str(guess[0])\n",
    "            actual_name = str(eval_labels[idx])\n",
    "        else:\n",
    "            guess_name = category_names[guess[0]]\n",
    "            actual_name = category_names[eval_labels[idx]]\n",
    "        sub.set_title(\"G: \" + guess_name + \" A: \" + actual_name)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
